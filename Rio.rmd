---
title: "R Notebook"
author: eyan
date: 25/01/2021
output: html_notebook
---
```{r}
library('tidyverse')
library('caret')
```
```{r}
customers <- read.csv('/home/eyan/Desktop/Rio/olist_customers_dataset.csv')
geolocation <- read.csv('/home/eyan/Desktop/Rio/olist_geolocation_dataset.csv')
order.items <- read.csv('/home/eyan/Desktop/Rio/olist_order_items_dataset.csv')
order.payments <- read.csv('/home/eyan/Desktop/Rio/olist_order_payments_dataset.csv')
order.reviews <- read.csv('/home/eyan/Desktop/Rio/olist_order_reviews_dataset.csv')
orders <- read.csv('/home/eyan/Desktop/Rio/olist_orders_dataset.csv')
sellers <- read.csv('/home/eyan/Desktop/Rio/olist_sellers_dataset.csv')
products <- read.csv('/home/eyan/Desktop/Rio/olist_products_dataset.csv')
product.category <- read.csv('/home/eyan/Desktop/Rio/product_category_name_translation.csv')
```
```{r}
head(customers)
```
```{r}
head(orders)
```
```{r}
prod <- products %>% inner_join(product.category)

olist <-customers %>%
        inner_join(orders) %>%
        inner_join(order.items) %>%
        inner_join(order.payments) %>%
        inner_join(order.reviews) %>%
        inner_join(sellers) %>%
        inner_join(prod) # %>%
        # inner_join(geolocation,by=c('customer_city'='geolocation_city'))
dim(olist)
```
```{r}
colSums(is.na(olist))
```
```{r}
olist[rownames(na.omit(olist)),]
# rownames(olist)
```
```{r}
str(olist)
```
```{r}
write.csv(olist,'olist.csv')
```
```{r}
head(olist)
```
```{r}
load('kira.RData')
```
```{r}
olist <- read.csv('Rio/olist.csv')
```
```{r}
colSums(is.na(olist))
```
```{r}
olist <- na.omit(olist)
anyDuplicated.data.frame(olist)
```
```{r}
olist <- subset(olist,select=-c(X,review_comment_title,review_comment_message,product_category_name,product_name_lenght,product_description_lenght))

Ids <- c(1,2,3,6,14,15,23,27)
olist <- olist[,-Ids]
```
```{r}
length(unique(olist$customer_unique_id))
```
```{r}
#get the numeric columns
numcol <- Filter(is.numeric,olist)
for (i in colnames(numcol)) {
  boxplot(numcol[[i]],main=names(numcol[i]))
}
```

UNIVARIATE ANALYSIS

```{r}
#Getting the general overview of the data
summary(olist)
```


```{r}
desc_stats <- data.frame(
  min = apply(numcol, 2, min),
  median = apply(numcol, 2, median),
  mean_df = apply(numcol, 2, mean),
  SD = apply(numcol, 2, sd),
  max = apply(numcol, 2, max)
)
desc_stats <- round(desc_stats,1)
head(desc_stats)
```
```{r}
# dim(olist)
#
# olist <- subset(olist,price<=5000)
# olist <- subset(olist,payment_value<=10000)
# olist <- subset(olist,product_weight_g<=35000)
#
# dim(olist)
```
```{r}
univar('price',olist)
```
```{r}
univar('order_item_id',olist,'category')
```
```{r}
univar('customer_state',olist,'category',flip = 'true')
```
```{r}
univar('order_status',olist,'category',flip='true')
```
```{r}
univar('order_item_id',olist,'category')
```
```{r}
univar('freight_value',olist)
```
```{r}
univar('payment_sequential',olist,'category')
```
```{r}
univar('payment_type',olist,'category')
```
```{r}
univar('payment_installments',olist,'category')
```
```{r}
univar('payment_value',olist)
```
```{r}
univar('review_score',olist,'category')
```
```{r}
univar('seller_state',olist,'category')
```
```{r}
univar('product_photos_qty',olist,'category')
```
```{r}
univar('product_weight_g',olist)
```
```{r}
univar('product_weight_g',olist)
```
```{r}
univar('product_length_cm',olist)
```
```{r}
univar('product_weight_cm',olist)
```
```{r}
univar('product_category_name_english',olist,'category')
```
```{r}
x <- olist[,c("customer_unique_id","product_category_name_english")] %>% group_by(customer_unique_id)
view(x)
```
```{r}
x <- olist[,c("product_photos_qty","payment_value")] %>% group_by(product_photos_qty) %>% summarise(Values = sum(payment_value))
plot(x)
```
```{r}
ggplot(olist,aes(product_photos_qty,fill=payment_value))+ geom_histogram()
```
```{r}
names <- c('order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','shipping_limit_date','review_creation_date','review_answer_timestamp')
for (name in names){
  olist[[name]] <- as.Date(olist[[name]])
}
```
```{r}
strings <- c(1,2,3,14,20,21,27)
for (i in strings){
  name <- colnames(olist[i])
  olist[name] <- label_encode(name,olist)
}
```
```{r}
x <- olist$order_purchase_timestamp
str(x[1])
```
```{r}
year <- as.numeric(format(x, format = "%Y"))
month <- as.numeric(format(x, format = "%m"))
day <- as.numeric(format(x, format = "%d"))
dates <- list('year'=year,'month'=month,'day'=day,'price'=olist$payment_value)
dates.prices <- as.data.frame(dates)
view(dates.prices)
```
```{r}
# R program to illustrate
# Polynomial regression
# theme_set(theme_classic())
# Split the data into training and test set
# set.seed(123)
sets <- get_train_validation(dates.prices)
train.data <- sets$Train
test.data  <- sets$Validation
```
```{r}
# Build the model
model <- lm(price ~ poly(year+month+day, degree = 4, raw = TRUE), data = train.data)
# Make predictions
predictions <- model.year %>% predict(test.data)
```
```{r}
# d <- test.data$price - predictions.year
# mse <- mean((d)^2)
# rmse <- sqrt(mse)
```
```{r}
# Model performance
modelPerfomance <- data.frame(
					RMSE = RMSE(predictions.year, test.data$price),
					R2 = R2(predictions.year, test.data$price)
				)
print(lm(price ~ year+month+day, data = train.data))
print(modelPerfomance)
```
**Start of polynomial**
```{r}
x <- olist$order_purchase_timestamp
year <- as.numeric(format(x, format = "%Y"))
month <- as.numeric(format(x, format = "%m"))
day <- as.numeric(format(x, format = "%d"))
dates <- list('year'=year,'month'=month,'day'=day,'price'=olist$payment_value)
dates.prices <- as.data.frame(dates)
view(dates.prices)
```
We decided to create models to predict the trend of sales over the years.
```{r}
year <- as.numeric(format(x, format = "%Y"))
month <- as.numeric(format(x, format = "%m"))
day <- as.numeric(format(x, format = "%d"))
dates <- list('year'=year,'month'=month,'day'=day,'price'=olist$payment_value)
dates.prices <- as.data.frame(dates)
head(dates.prices)
```
```{r}
get_train_validation <- function (dataset){
  # Geting the row numbers for train sample (80% of the dataset)
  train <- sample(seq_len(nrow(dataset)), size = ceiling(0.80*nrow(dataset)), replace = FALSE)
  # training set == part of the dataset in the train sample
  train_set <- dataset[train,]
  # Validation set == part of the dataset not in the train sample
  Validation_set <- dataset[-train,]
  # fix for R not accepting multiple argument returns
  sets <- list("Train" = train_set, "Validation" = Validation_set)
  return (sets)
}
POLY <- function (set,what,deg=2){
  # Geting the train and test sets
  train.data <- set$Train
  test.data  <- set$Validation
  # Build the model
  if(what=='year'){
    model <- lm(price ~ poly(year, degree = deg, raw = TRUE), data = train.data)

  }else if(what=='month'){
    model <- lm(price ~ poly(month, degree = deg, raw = TRUE), data = train.data)

  }else if(what=='day'){
    model <- lm(price ~ poly(day, degree = deg, raw = TRUE), data = train.data)

  }
  # Make predictions
  predictions <- model %>% predict(test.data)
  #Get the rmse and r2 scores of the model
  RMSE <- RMSE(predictions, test.data$price)
  R2 <- R2(predictions, test.data$price)
  result <- list('model'=model,'rmse'=RMSE,'r2'=R2)
  return(result)
}
predict_ <- function (model,object,lists){
  #Creating a dataframe from the list provided
  if(object=='year'){
    nw <- data.frame('year'=lists)
  }else
  if(object=='month'){
    nw <- data.frame('month'=lists)
  }else
  if(object=='day'){
    nw <- data.frame('day'=lists)
  }
  #Predicting the value(s) in the dataframe using the selected model
  xpr <- suppressWarnings(predict(model,nw,type = 'response'))
  return (xpr)#Return the prediction
}
```
```{r}
rmse_ <- 1000
for (i in 2:10){
  sets <- get_train_validation(dates.prices)
  res <- suppressWarnings(POLY(sets,'year',deg = i))
  if (res$rmse < rmse_){
    best.year_model <- res$model
    degree_ <- i
    rmse_ <- res$rmse
  }
}
print(paste('best degrees for years at',degree_,'degrees'))
```
```{r}
predictions_years <- predict_(best.year_model, 'year', 2016:2024)
plot(predictions_years)
```
The model predicted a rising trend in the prices for the years to come
```{r}
rmse_ <- 1000
for (i in 2:10){
  sets <- get_train_validation(dates.prices)
  res <- POLY(sets,'month',deg =i)
  if (res$rmse < rmse_){
    best.month_model <- res$model
    degree_ <- i
    rmse_ <- res$rmse
  }
}
print(paste('best degrees for months at',degree_,'degrees'))
```
```{r}
predictions_months <- predict_(best.month_model, 'month', 1:12)
plot(predictions_months)
```
The model predicts sales spikes in april and september.
```{r}
rmse_ <- 1000
for (i in 2:10){
  sets <- get_train_validation(dates.prices)
  res <- POLY(sets,'day',deg =i)
  if (res$rmse < rmse_){
    best.day_model <- res$model
    degree_ <- i
    rmse_ <- res$rmse
  }
}
print(paste('best degrees for days at',degree_,'degrees'))
```
```{r}
predictions_days <- predict_(best.day_model, 'day', 1:30)
plot(predictions_days)
```
The model predicts spikes in sales every tenth day and a drop in the sales every day ending in a 5 days


**End of polynomial**

```{r}
olist.no <- na.omit(olist[,-c(4:8,10,18,19)])
```
```{r}
# Geting the principle components from the supermarkets dataset.
results <- prcomp(olist.no, center = TRUE, scale. = TRUE)
summary(results)
```
```{r}
screeplot(results, type = "l", npcs = 19, main = "Screeplot of the first 19 Principal components")
abline(h = 0.8, col="red", lty=5)
```
```{r}
pca.red <- data.frame(results$x)
view(pca.red)
```
```{r}
view(pca.red[, 1:11])
```
<h1>**Basket analysis**</h1>

```{r}
library('arules')
```
```{r}
items<-as.data.frame(itemLabels(olist$product_category_name_english))
colnames(items) <- "Item"
head(items)
```
**Group dataset by months , days or years then use that to predict sales in months,years,days etc ðŸ˜… i hope ntakumbuka what i meant by this**
```{r}
save(POLY,predict_,predict_all,get_train_validation,file = 'Polynomial.RData')
```
